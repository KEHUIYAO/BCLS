{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupNorm will be applied!\n",
      "GroupNorm will be applied!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kehuiyao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/kehuiyao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/kehuiyao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/kehuiyao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/kehuiyao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/kehuiyao/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "\n",
      "  | Name          | Type    | Params\n",
      "------------------------------------------\n",
      "0 | encoder       | Encoder | 27.4 K\n",
      "1 | decoder       | Decoder | 27.4 K\n",
      "2 | net           | ED      | 54.8 K\n",
      "3 | loss_function | MSELoss | 0     \n",
      "------------------------------------------\n",
      "54.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "54.8 K    Total params\n",
      "0.219     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kehuiyao/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n",
      "/Users/kehuiyao/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "/Users/kehuiyao/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:103: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f'The dataloader, {name}, does not have many workers which may be a bottleneck.'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98ea25e26724054993aa6ffe5e1a90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kehuiyao/anaconda3/lib/python3.7/site-packages/pytorch_lightning/core/lightning.py:169: LightningDeprecationWarning: The `LightningModule.datamodule` property is deprecated in v1.3 and will be removed in v1.5. Access the datamodule through using `self.trainer.datamodule` instead.\n",
      "  \"The `LightningModule.datamodule` property is deprecated in v1.3 and will be removed in v1.5.\"\n",
      "/Users/kehuiyao/anaconda3/lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "/Users/kehuiyao/anaconda3/lib/python3.7/site-packages/torch/jit/_trace.py:985: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\n",
      "With rtol=1e-05 and atol=1e-05, found 31395 element(s) (out of 40960) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.6735424399375916 (0.0 vs. 0.6735424399375916), which occurred at index (0, 2, 0, 9, 32).\n",
      "  _module_class,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kehuiyao/anaconda3/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:897: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn('Detected KeyboardInterrupt, attempting graceful shutdown...')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import torchvision\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import gzip\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "def load_mnist(root, image_size=28):\n",
    "    # Load MNIST dataset for generating training data.\n",
    "    path = os.path.join(root, 'train-images-idx3-ubyte.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        mnist = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "        mnist = mnist.reshape(-1, image_size, image_size)\n",
    "    return mnist\n",
    "\n",
    "class MovingMNIST(data.Dataset):\n",
    "    def __init__(self, root, n_frames_input, n_frames_output, num_digits=2, image_size=64, digit_size=28, N=10,\n",
    "                 transform=None):\n",
    "        '''\n",
    "        param num_objects: a list of number of possible objects.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.mnist = load_mnist(root)\n",
    "        self.length = N\n",
    "        self.n_frames_input = n_frames_input\n",
    "        self.n_frames_output = n_frames_output\n",
    "        self.n_frames_total = self.n_frames_input + self.n_frames_output\n",
    "        self.transform = transform\n",
    "        # For generating data\n",
    "        self.image_size_ = image_size\n",
    "        self.digit_size_ = digit_size\n",
    "        self.step_length_ = 0.1\n",
    "        self.num_digits = num_digits\n",
    "\n",
    "    def get_random_trajectory(self, seq_length):\n",
    "        ''' Generate a random sequence of a MNIST digit '''\n",
    "        canvas_size = self.image_size_ - self.digit_size_\n",
    "        x = random.random()\n",
    "        y = random.random()\n",
    "        theta = random.random() * 2 * np.pi\n",
    "        v_y = np.sin(theta)\n",
    "        v_x = np.cos(theta)\n",
    "\n",
    "        start_y = np.zeros(seq_length)\n",
    "        start_x = np.zeros(seq_length)\n",
    "        for i in range(seq_length):\n",
    "            # Take a step along velocity.\n",
    "            y += v_y * self.step_length_\n",
    "            x += v_x * self.step_length_\n",
    "\n",
    "            # Bounce off edges.\n",
    "            if x <= 0:\n",
    "                x = 0\n",
    "                v_x = -v_x\n",
    "            if x >= 1.0:\n",
    "                x = 1.0\n",
    "                v_x = -v_x\n",
    "            if y <= 0:\n",
    "                y = 0\n",
    "                v_y = -v_y\n",
    "            if y >= 1.0:\n",
    "                y = 1.0\n",
    "                v_y = -v_y\n",
    "            start_y[i] = y\n",
    "            start_x[i] = x\n",
    "\n",
    "        # Scale to the size of the canvas.\n",
    "        start_y = (canvas_size * start_y).astype(np.int32)\n",
    "        start_x = (canvas_size * start_x).astype(np.int32)\n",
    "        return start_y, start_x\n",
    "\n",
    "    def generate_moving_mnist(self):\n",
    "        '''\n",
    "        Get random trajectories for the digits and generate a video.\n",
    "        '''\n",
    "        data = np.zeros((self.n_frames_total, self.image_size_, self.image_size_), dtype=np.float32)\n",
    "        for n in range(self.num_digits):\n",
    "            # Trajectory\n",
    "            start_y, start_x = self.get_random_trajectory(self.n_frames_total)\n",
    "            ind = random.randint(0, self.mnist.shape[0] - 1)\n",
    "            digit_image = self.mnist[ind]\n",
    "            for i in range(self.n_frames_total):\n",
    "                top = start_y[i]\n",
    "                left = start_x[i]\n",
    "                bottom = top + self.digit_size_\n",
    "                right = left + self.digit_size_\n",
    "                # Draw digit\n",
    "                data[i, top:bottom, left:right] = np.maximum(data[i, top:bottom, left:right], digit_image)\n",
    "\n",
    "        data = data[..., np.newaxis]\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        length = self.n_frames_input + self.n_frames_output\n",
    "\n",
    "        # Sample number of objects\n",
    "        # Generate data on the fly\n",
    "        images = self.generate_moving_mnist()\n",
    "\n",
    "        # if self.transform is not None:\n",
    "        #     images = self.transform(images)\n",
    "\n",
    "        r = 1\n",
    "        w = int(64 / r)\n",
    "        images = images.reshape((length, w, r, w, r)).transpose(0, 2, 4, 1, 3).reshape((length, r * r, w, w))\n",
    "\n",
    "        input = images[:self.n_frames_input]\n",
    "        if self.n_frames_output > 0:\n",
    "            output = images[self.n_frames_input:length]\n",
    "        else:\n",
    "            output = []\n",
    "\n",
    "        frozen = input[-1]\n",
    "        # add a wall to input data\n",
    "        # pad = np.zeros_like(input[:, 0])\n",
    "        # pad[:, 0] = 1\n",
    "        # pad[:, pad.shape[1] - 1] = 1\n",
    "        # pad[:, :, 0] = 1\n",
    "        # pad[:, :, pad.shape[2] - 1] = 1\n",
    "        #\n",
    "        # input = np.concatenate((input, np.expand_dims(pad, 1)), 1)\n",
    "\n",
    "        output = torch.from_numpy(output / 255.0).contiguous().float()\n",
    "        input = torch.from_numpy(input / 255.0).contiguous().float()\n",
    "        # print()\n",
    "        # print(input.size())\n",
    "        # print(output.size())\n",
    "\n",
    "        out = [idx, output, input, frozen, np.zeros(1)]\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "epochs = 20\n",
    "frames_input = 10\n",
    "frames_output = 10\n",
    "\n",
    "\n",
    "trainFolder = MovingMNIST(root='data/',\n",
    "                          n_frames_input=frames_input,\n",
    "                          n_frames_output=frames_output,\n",
    "                          image_size=64,\n",
    "                          digit_size=28,\n",
    "                          N=10,\n",
    "                          transform=None\n",
    "                          )\n",
    "\n",
    "validFolder = MovingMNIST(root='data/',\n",
    "                          n_frames_input=frames_input,\n",
    "                          n_frames_output=frames_output,\n",
    "                          image_size=64,\n",
    "                          digit_size=28,\n",
    "                          N=10,\n",
    "                          transform=None\n",
    "                          )\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(trainFolder,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "validLoader = torch.utils.data.DataLoader(validFolder,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "train_batch_per_epoch = len(trainFolder)\n",
    "valid_batch_per_epoch = len(validLoader)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class BayesianDropout(nn.Module):\n",
    "    \"\"\"\n",
    "     Implementation of BAYESIAN CONVOLUTIONAL NEURAL NETWORKS WITH BERNOULLI APPROXIMATE VARIATIONAL INFERENCE by Yarin Gal and the core idea is to set an approximating distribution modelling each kernel-patch pair with a distinct random variable, and this distribution randomly sets kernels to zero for different patches, which results in the equivalent explanation of applying dropout for each element in the tensor y before pooling. So implementing the bayesian CNN is therefore as simple as using dropout after every convolution layer before pooling\n",
    "    \"\"\"\n",
    "    def __init__(self, dropout, x):\n",
    "        \"generate dropout mask using x's shape\"\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.m = x.new_empty(x.size()).bernoulli_(1 - dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"apply the dropout mask to x\"\n",
    "        x = x.masked_fill(self.m == 0, 0)\n",
    "        return x\n",
    "\n",
    "class CLSTM_cell(nn.Module):\n",
    "    \"\"\"\n",
    "    singler layer of ConvLSTMCell\n",
    "    \"\"\"\n",
    "    def __init__(self, shape, input_channels, filter_size, num_features, dropout_rate=0):\n",
    "        super(CLSTM_cell, self).__init__()\n",
    "\n",
    "        # (H, W)\n",
    "        self.shape = shape\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.filter_size = filter_size\n",
    "        self.num_features = num_features\n",
    "\n",
    "        # in this way the output has the same size\n",
    "        self.padding = (filter_size - 1) // 2\n",
    "\n",
    "        # input_dim+hidden_dim -> 4*hidden_dim\n",
    "        self.conv = nn.Conv2d(self.input_channels + self.num_features,\n",
    "                      4 * self.num_features, self.filter_size, 1,\n",
    "                      self.padding)\n",
    "\n",
    "        # apply GroupNorm, the input channels are separated into num_groups groups, each containing num_channels / num_groups channels. The mean and standard-deviation are calculated separately over the each group.\n",
    "        if 4 * self.num_features < 32:\n",
    "            print(\"GroupNorm will not be applied, require more output channels to apply GroupNorm!\")\n",
    "        else:\n",
    "            print(\"GroupNorm will be applied!\")\n",
    "            self.groupnorm = nn.GroupNorm(4 * self.num_features // 32, 4 * self.num_features)\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def forward(self, inputs=None, hidden_state=None, seq_len=10):\n",
    "        \"\"\"\n",
    "        inputs is of size (S, B, C, H, W)\n",
    "        hidden state is of size (B, C_new, H, W)\n",
    "        seq_len=10 for moving_mnist\n",
    "        return a turple of (a, (b, c)), where a is of shape (S, B, C_new, H, W); b and c are of shape (B, C_new, H, W)\n",
    "        \"\"\"\n",
    "\n",
    "        # if hidden_state is None, initialize it with zeros\n",
    "        if hidden_state is None:\n",
    "            hx = torch.zeros(inputs.size(1), self.num_features, self.shape[0],\n",
    "                             self.shape[1])\n",
    "            cx = torch.zeros(inputs.size(1), self.num_features, self.shape[0],\n",
    "                             self.shape[1])\n",
    "        else:\n",
    "            hx, cx = hidden_state\n",
    "\n",
    "        output_inner = []\n",
    "\n",
    "        # apply dropout (combining CNN version and RNN version of bayesian dropout)\n",
    "        if self.dropout_rate == 0:\n",
    "            pass\n",
    "        else:\n",
    "            self.dropout_layer = BayesianDropout(self.dropout_rate, torch.zeros(hx.size(0),self.num_features*4, self.shape[0], self.shape[1]))\n",
    "\n",
    "        # for each time step, perform a CNN on a slice of the sequence of images and record the hidden state and cell state\n",
    "        for index in range(seq_len):\n",
    "            if inputs is None:\n",
    "                x = torch.zeros(hx.size(0), self.input_channels, self.shape[0],\n",
    "                                self.shape[1])\n",
    "            else:\n",
    "                x = inputs[index, ...]\n",
    "\n",
    "            # combining input and last hidden state\n",
    "            combined = torch.cat((x, hx), 1)\n",
    "\n",
    "            # apply CNN forward pass\n",
    "            gates = self.conv(combined)  # gates: (B, num_features*4, H, W)\n",
    "\n",
    "            # apply group norm\n",
    "            gates = self.groupnorm(gates)\n",
    "\n",
    "            # apply the same dropout mask at each time step\n",
    "            if self.dropout_rate == 0:\n",
    "                pass\n",
    "            else:\n",
    "                gates = self.dropout_layer(gates)\n",
    "\n",
    "            # it should return 4 tensors: i,f,g,o following the literature of LSTM\n",
    "            ingate, forgetgate, cellgate, outgate = torch.split(\n",
    "                gates, self.num_features, dim=1)\n",
    "            ingate = torch.sigmoid(ingate)\n",
    "            forgetgate = torch.sigmoid(forgetgate)\n",
    "            cellgate = torch.tanh(cellgate)\n",
    "            outgate = torch.sigmoid(outgate)\n",
    "\n",
    "            cy = (forgetgate * cx) + (ingate * cellgate)\n",
    "            hy = outgate * torch.tanh(cy)\n",
    "            output_inner.append(hy)\n",
    "            hx = hy\n",
    "            cx = cy\n",
    "\n",
    "        return torch.stack(output_inner), (hy, cy)\n",
    "\n",
    "class ConvCell(nn.Module):\n",
    "    \"\"\"\n",
    "    used to apply separate CNN for images at different time steps\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, dropout_rate=0):\n",
    "        super().__init__()\n",
    "        self.pooling_layer = nn.MaxPool2d(kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.relu_layer = nn.ReLU()\n",
    "\n",
    "        # H_out = (H_in + 2 * padding - (kernel_size - 1) - 1) / stride\n",
    "        # W_out can be calculated in the same way\n",
    "        self.conv2d = nn.Conv2d(in_channels=in_channels,\n",
    "                                out_channels=out_channels,\n",
    "                                kernel_size=kernel_size,\n",
    "                                stride=stride,\n",
    "                                padding=padding\n",
    "                                )\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"x is of size B, S, C, H, W\"\n",
    "\n",
    "        # make x to be size B*S, C, H, W\n",
    "        B, S, C, H, W = x.size()\n",
    "        x = torch.reshape(x, (-1, C, H, W))\n",
    "\n",
    "        # forward through CNN\n",
    "        x = self.conv2d(x)\n",
    "\n",
    "        # apply CNN version of bayesian dropout\n",
    "        if self.dropout_rate == 0:\n",
    "            pass\n",
    "        else:\n",
    "            dropout_layer= BayesianDropout(self.dropout_rate, x)\n",
    "            x = dropout_layer(x)\n",
    "\n",
    "        # apply maxpooling\n",
    "        x = self.pooling_layer(x)\n",
    "\n",
    "        # apply non-linearity function\n",
    "        x = self.relu_layer(x)\n",
    "\n",
    "        # make x to be size B, S, C_new, H_new, W_new\n",
    "        C_new = x.size(1)\n",
    "        H_new = x.size(2)\n",
    "        W_new = x.size(3)\n",
    "        x = torch.reshape(x, (B, S, C_new, H_new, W_new))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    used to encode the data.\n",
    "    consists of multiple ConvLSTM cells\n",
    "    \"\"\"\n",
    "    def __init__(self, rnns):\n",
    "        super().__init__()\n",
    "        self.blocks = len(rnns)\n",
    "\n",
    "        # rnn is a ConvLSTM cell\n",
    "        for index, rnn in enumerate(rnns, 1):\n",
    "            # index sign from 1\n",
    "            setattr(self, 'rnn' + str(index), rnn)\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        inputs = inputs.transpose(0, 1)  # to S,B,1,64,64\n",
    "        hidden_states = []\n",
    "\n",
    "        for i in range(1, self.blocks + 1):\n",
    "            cur_rnn = getattr(self, 'rnn' + str(i))\n",
    "            inputs, state_stage = cur_rnn(inputs)\n",
    "            hidden_states.append(state_stage)\n",
    "\n",
    "        return tuple(hidden_states)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    used to decode data.\n",
    "    consists of multiple ConvLSTM cells and one ConvCell mapping the hidden state to output\n",
    "    \"\"\"\n",
    "    def __init__(self, rnns, cnn):\n",
    "        super().__init__()\n",
    "        self.blocks = len(rnns)\n",
    "\n",
    "        for index, rnn in enumerate(rnns, 1):\n",
    "            setattr(self, 'rnn' + str(index), rnn)\n",
    "\n",
    "        # the output layer is a ConvCell\n",
    "        self.output_layer = cnn\n",
    "\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        cur_rnn = getattr(self, 'rnn1')\n",
    "        inputs, _ = cur_rnn(None, hidden_states[0], seq_len=10)\n",
    "\n",
    "        for i in list(range(1, self.blocks)):\n",
    "            cur_rnn = getattr(self, 'rnn' + str(i+1))\n",
    "            inputs, _ = cur_rnn(inputs, hidden_states[i], seq_len=10)\n",
    "        inputs = inputs.transpose(0, 1)  # to B,S,C,64,64\n",
    "\n",
    "        outputs = self.output_layer(inputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "\n",
    "class ED(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, input):\n",
    "        state = self.encoder(input)\n",
    "        output = self.decoder(state)\n",
    "        return output\n",
    "\n",
    "\n",
    "class LightningConvLstm(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    functions includes:\n",
    "    model checkpointing\n",
    "    built-in gpu training\n",
    "    logging\n",
    "    visualization\n",
    "    early stopping\n",
    "    distributed training\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder_rnns, decoder_rnns, output_cnn):\n",
    "        super(LightningConvLstm, self).__init__()\n",
    "        self.encoder = Encoder(encoder_rnns)\n",
    "        self.decoder = Decoder(decoder_rnns, output_cnn)\n",
    "        self.net = ED(self.encoder, self.decoder)\n",
    "        self.loss_function = nn.MSELoss()\n",
    "\n",
    "    def simple_plot(self, x, pred):\n",
    "\n",
    "        # detach\n",
    "        x = torch.Tensor.cpu(x).detach()\n",
    "        pred = torch.Tensor.cpu(pred).detach()\n",
    "\n",
    "        grid_x = torchvision.utils.make_grid(x)\n",
    "        grid_pred = torchvision.utils.make_grid(pred)\n",
    "\n",
    "        self.logger.experiment.add_image(\"True\", grid_x, self.current_epoch)\n",
    "        self.logger.experiment.add_image(\"Pred\", grid_pred, self.current_epoch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \" x is of shape (B, S, C, J, W)\"\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (idx, targetVar, inputVar, _, _) = batch\n",
    "        pred = self.forward(inputVar)  # (B,S,C,H,W)\n",
    "        loss = self.loss_function(pred, targetVar)\n",
    "        self.log('train_loss', loss)\n",
    "        \n",
    "        # if it's the last batch in the current epoch, record the true image sequence and the predicted image sequences\n",
    "        if batch_idx == (train_batch_per_epoch - 1):\n",
    "            # add one image sequence in a batch and the corresponding predicted image\n",
    "            # only use the first image sequence in a batch\n",
    "            pred = pred[0, ...]\n",
    "            targetVar = targetVar[0, ...]\n",
    "            self.simple_plot(targetVar, pred)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        \"the function is called after every epoch is completed\"\n",
    "        \n",
    "        # add computational graph\n",
    "        if (self.current_epoch == 1):\n",
    "            sampleImg = torch.rand((1, 10, 1, 64, 64))\n",
    "            self.logger.experiment.add_graph(LightningConvLstm(encoder_rnns, decoder_rnns, output_cnn), sampleImg)\n",
    "        \n",
    "        \n",
    "        # calculate the average loss\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        \n",
    "        # logging using tensorboard logger\n",
    "        self.logger.experiment.add_scalar('Loss/Train', avg_loss, self.current_epoch)\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        (idx, targetVar, inputVar, _, _) = batch\n",
    "        pred = self.forward(inputVar)  # B,S,C,H,W\n",
    "        loss = self.loss_function(pred, targetVar)\n",
    "\n",
    "        self.log('validation_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=4)\n",
    "        return {'optimizer': optimizer,\n",
    "                'lr_scheduler': {'scheduler': scheduler,\n",
    "                                 'monitor': \"validation_loss\"}}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train\n",
    "# encoder_rnns = [CLSTM_cell(shape=(64, 64), input_channels=1, filter_size=9, num_features=64, dropout_rate=0.1),\n",
    "#                 CLSTM_cell(shape=(64, 64), input_channels=64, filter_size=5, num_features=16, dropout_rate=0.1)]\n",
    "# decoder_rnns = [CLSTM_cell(shape=(64, 64), input_channels=1, filter_size=9, num_features=64, dropout_rate=0.1),\n",
    "#                 CLSTM_cell(shape=(64, 64), input_channels=64, filter_size=5, num_features=16, dropout_rate=0.1)]\n",
    "# output_cnn = ConvCell(in_channels=16, out_channels=1, kernel_size=1, stride=1, padding=0, dropout_rate=0.1)\n",
    "\n",
    "encoder_rnns = [CLSTM_cell(shape=(64, 64), input_channels=1, filter_size=5, num_features=16, dropout_rate=0.1)]\n",
    "decoder_rnns = [CLSTM_cell(shape=(64, 64), input_channels=1, filter_size=5, num_features=16, dropout_rate=0.1)]\n",
    "                \n",
    "output_cnn = ConvCell(in_channels=16, out_channels=1, kernel_size=1, stride=1, padding=0, dropout_rate=0.1)\n",
    "\n",
    "\n",
    "\n",
    "model = LightningConvLstm(encoder_rnns, decoder_rnns, output_cnn)\n",
    "#model = model.load_from_checkpoint(checkpoint_path='/Users/kehuiyao/Desktop/ConvLSTM-PyTorch/lightning_logs/version_5/checkpoints/epoch=12-step=129.ckpt')\n",
    "logger = TensorBoardLogger('tb_logs',name='my_model_run_name')\n",
    "trainer = pl.Trainer(max_epochs=100, logger=logger)\n",
    "trainer.fit(model, trainLoader, validLoader)\n",
    "\n",
    "\n",
    "# load tensorboard\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir tb_logs/my_model_run_name\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
